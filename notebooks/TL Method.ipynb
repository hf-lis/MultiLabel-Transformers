{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import BCELoss\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from transformers import *\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Get cuda if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "for index in range(n_gpu):\n",
    "    print(torch.cuda.get_device_name(index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "csv_path = Path(\"path_to_CSVs\")\n",
    "delimiter='\\t' # default delimiter is comma\n",
    "df_train = pd.read_csv(csv_path/'train.csv', delimiter=delimiter) \n",
    "cols = df_train.columns\n",
    "label_cols = list(cols[3:])\n",
    "num_labels = len(label_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.load(f'dataloaders/train_data_loader-{batch_size}-{max_length}')\n",
    "validation_dataloader = torch.load(f'dataloaders/validation_data_loader-{batch_size}-{max_length}')\n",
    "test_dataloader = torch.load(f'dataloaders/test_data_loader-{batch_size}-{max_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': train_dataloader,\n",
    "    'dev': validation_dataloader,\n",
    "    'test': test_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingFace_model_name = \"flaubert/flaubert_base_cased\"\n",
    "dataset_name = \"my dataset\"\n",
    "model_name = \"FlauBERT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(method, f1, acc, precision, recall):\n",
    "    print('\\n'+method+' :')\n",
    "    print('Micro F1-Score =', f1)\n",
    "    print('Accuracy =', acc)\n",
    "    print('Micro Avg : precision =', precision, 'recall =', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(true_bools, pred_bools):\n",
    "    clf_report_optimized = classification_report(true_bools, pred_bools, target_names=label_cols, digits=5, zero_division=1, output_dict=True)\n",
    "    micro_avg = clf_report_optimized['micro avg']\n",
    "    f1 = f1_score(true_bools, pred_bools,average='micro')*100\n",
    "    acc = accuracy_score(true_bools, pred_bools)*100\n",
    "    precision = micro_avg['precision']*100\n",
    "    recall = micro_avg['recall']*100\n",
    "    \n",
    "    return f1, acc, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(huggingFace_model_name, num_labels=num_labels)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, out_features):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.dense_1 = torch.nn.Linear(in_features=input_size, out_features=out_features, bias=True)\n",
    "        self.dense_2 = torch.nn.Linear(in_features=out_features, out_features=out_features, bias=True)\n",
    "        self.activation_2 = torch.nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.dense_1(x)\n",
    "        out2 = self.dense_2(out)\n",
    "        out2 = self.activation_2(out2)\n",
    "        return out, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.sequence_summary.summary = Classifier(input_size=768, out_features=num_labels)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting custom optimization parameters. You may implement a scheduler here as well.\n",
    "param_optimizer = list(model.named_parameters())\n",
    "\n",
    "# every layer except the last one\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not 'dense_2' in n]}\n",
    "]\n",
    "\n",
    "#isolate the last layer\n",
    "optimizer_grouped_parameters_thresh = [\n",
    "    {'params': [p for n, p in param_optimizer if 'dense_2' in n]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=1e-5)\n",
    "optimizer_thresh = torch.optim.AdamW(optimizer_grouped_parameters_thresh, lr=1e-5)\n",
    "\n",
    "classification_criterion = torch.nn.BCEWithLogitsLoss() \n",
    "threshold_criterion = torch.nn.BCELoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "best_dev_f1 = -1\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wandb\n",
    "# a wandb account is needed to log training metrics\n",
    "wandb.login()\n",
    "config = {\"epochs\": epochs, \"batch_size\": batch_size, \"seq_max_length\": max_length,\n",
    "          \"lr_cls\": 2e-5, \"threshold\": threshold,\n",
    "         \"optimizer\": \"AdamW\"}\n",
    "config.update({\"dataset\": dataset_name})\n",
    "\n",
    "mode = \"disabled\"\n",
    "wandb.init(project=\"myProject\", entity=\"myEntity\", name=\"RunName\", config=config) # project info must be modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trange is a tqdm wrapper around the normal python range\n",
    "for epoch_num in trange(epochs, desc=\"Epoch\", position=0):\n",
    "    \n",
    "    for phase in tqdm(['train', 'dev'], leave=False, desc='Phases', position=0):\n",
    "\n",
    "        # Tracking variables\n",
    "        true_labels,pred_labels = [], [] \n",
    "        epoch_loss, cls_loss, thresh_loss = 0, 0, 0 #running losses\n",
    "        epoch_steps = 0\n",
    "        \n",
    "        if phase == 'train': \n",
    "            model.train()\n",
    "            \n",
    "        if phase == 'dev':\n",
    "            model.eval()\n",
    "            \n",
    "        for step, batch in enumerate(tqdm(dataloaders[phase], leave=False, desc=f\"{phase.capitalize()} Dataloader\", position=0)):\n",
    "\n",
    "            # Add batch to device\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Unpack the inputs from our dataloader\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "            # Forward pass for multilabel classification\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(b_input_ids, attention_mask=b_input_mask)[0]\n",
    "                classification_logits, thresholding_logits = outputs     \n",
    "                \n",
    "            del b_input_ids, b_input_mask, outputs\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            #loss calculation\n",
    "            classification_loss = classification_criterion(classification_logits, b_labels.type_as(classification_logits))\n",
    "            thresholding_loss = threshold_criterion(thresholding_logits, b_labels.type_as(thresholding_logits))\n",
    "            loss = classification_loss + thresholding_loss\n",
    "            \n",
    "            if phase == 'train': \n",
    "\n",
    "                # Clear out the gradients \n",
    "                optimizer.zero_grad()\n",
    "                optimizer_thresh.zero_grad()\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                    \n",
    "                # Update parameters and take a step using the computed gradient\n",
    "                optimizer.step()\n",
    "                optimizer_thresh.step()\n",
    "\n",
    "            # Update tracking variables\n",
    "            epoch_loss += loss.item()\n",
    "            cls_loss += classification_loss.item()\n",
    "            thresh_loss += thresholding_loss.item()\n",
    "            epoch_steps += 1\n",
    "            \n",
    "            # Batch Predictions/true_labels\n",
    "            pred_label = thresholding_logits.detach().to('cpu').numpy()\n",
    "            b_labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "            true_labels.append(b_labels)\n",
    "            pred_labels.append(pred_label)\n",
    "            \n",
    "\n",
    "        # Get Epoch Loss\n",
    "        epoch_loss = epoch_loss/epoch_steps\n",
    "        cls_loss = cls_loss/epoch_steps\n",
    "        thresh_loss = thresh_loss/epoch_steps\n",
    "        \n",
    "        # Get Epoch Metrics\n",
    "        # Make list out of all the batch predictions/true_labels\n",
    "        pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "        true_labels = [item for sublist in true_labels for item in sublist]\n",
    "        true_bools = true_labels \n",
    "\n",
    "        # TL Metrics \n",
    "        pred_bools = [pl>threshold for pl in pred_labels] \n",
    "        f1_accuracy, acc, precision, recall = get_metrics(true_bools, pred_bools)\n",
    "\n",
    "        # Log Epoch Metrics\n",
    "        metrics = {\n",
    "            'F1_score': f1_accuracy,\n",
    "            'Accuracy': acc,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'epoch_loss': epoch_loss,\n",
    "            'cls_loss': cls_loss,\n",
    "            'thresh_loss': thresh_loss\n",
    "        }\n",
    "        wandb.log({f'{phase.capitalize()}': metrics}, commit=False)\n",
    "        # print_results(\"TL\", f1_sgo, acc_sgo, precision_sgo, recall_sgo)\n",
    "\n",
    "        # Save model if valid performances are better\n",
    "        if phase == 'dev':\n",
    "            if f1_accuracy > best_dev_f1 :\n",
    "                best_dev_f1 = f1_accuracy\n",
    "                torch.save(model.state_dict(), 'state_dicts/'+model_name+'_'+dataset_name+'_best_model_weights_tl.pt')\n",
    "\n",
    "    wandb.log(data={}, commit=True)\n",
    "    \n",
    "# save last model\n",
    "torch.save(model.state_dict(), 'state_dicts/last_'+ model_name +'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
