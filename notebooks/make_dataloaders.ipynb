{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "from transformers import *\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSV to DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = Path(\"path_to_CSVs\")\n",
    "delimiter='\\t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11035, 203)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HAL_ID</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>chim.anal</th>\n",
       "      <th>chim.cata</th>\n",
       "      <th>chim.chem</th>\n",
       "      <th>chim.cris</th>\n",
       "      <th>chim.geni</th>\n",
       "      <th>chim.inor</th>\n",
       "      <th>chim.mate</th>\n",
       "      <th>...</th>\n",
       "      <th>spi.other</th>\n",
       "      <th>spi.plasma</th>\n",
       "      <th>spi.signal</th>\n",
       "      <th>spi.tron</th>\n",
       "      <th>stat.ap</th>\n",
       "      <th>stat.co</th>\n",
       "      <th>stat.me</th>\n",
       "      <th>stat.ml</th>\n",
       "      <th>stat.ot</th>\n",
       "      <th>stat.th</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hal-01397119</td>\n",
       "      <td>Fluidification du trafic Transilien : approche...</td>\n",
       "      <td>Avec plus d'un million de voyageurs quotidiens...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hal-03203665</td>\n",
       "      <td>Choix et attentes des enseignants de mathémati...</td>\n",
       "      <td>L'objectif de ce séminaire est de présenter le...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inria-00386758</td>\n",
       "      <td>Apport de l'ACP probabiliste pour la gestion d...</td>\n",
       "      <td>Dans cette présentation, nous nous intéressons...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inria-00386607</td>\n",
       "      <td>Estimation Monte Carlo dans les processus ponc...</td>\n",
       "      <td>Nous proposons une approche de modélisation pa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inria-00494789</td>\n",
       "      <td>Convergence de la constante de Cheeger de grap...</td>\n",
       "      <td>Nous nous intéressons dans ce travail aux ense...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           HAL_ID                                              title  \\\n",
       "0    hal-01397119  Fluidification du trafic Transilien : approche...   \n",
       "1    hal-03203665  Choix et attentes des enseignants de mathémati...   \n",
       "2  inria-00386758  Apport de l'ACP probabiliste pour la gestion d...   \n",
       "3  inria-00386607  Estimation Monte Carlo dans les processus ponc...   \n",
       "4  inria-00494789  Convergence de la constante de Cheeger de grap...   \n",
       "\n",
       "                                            abstract  chim.anal  chim.cata  \\\n",
       "0  Avec plus d'un million de voyageurs quotidiens...          0          0   \n",
       "1  L'objectif de ce séminaire est de présenter le...          0          0   \n",
       "2  Dans cette présentation, nous nous intéressons...          0          0   \n",
       "3  Nous proposons une approche de modélisation pa...          0          0   \n",
       "4  Nous nous intéressons dans ce travail aux ense...          0          0   \n",
       "\n",
       "   chim.chem  chim.cris  chim.geni  chim.inor  chim.mate  ...  spi.other  \\\n",
       "0          0          0          0          0          0  ...          0   \n",
       "1          0          0          0          0          0  ...          0   \n",
       "2          0          0          0          0          0  ...          0   \n",
       "3          0          0          0          0          0  ...          0   \n",
       "4          0          0          0          0          0  ...          0   \n",
       "\n",
       "   spi.plasma  spi.signal  spi.tron  stat.ap  stat.co  stat.me  stat.ml  \\\n",
       "0           0           0         0        0        0        0        0   \n",
       "1           0           0         0        0        0        0        0   \n",
       "2           0           0         0        0        0        0        0   \n",
       "3           0           0         0        0        0        0        0   \n",
       "4           0           0         0        0        0        0        0   \n",
       "\n",
       "   stat.ot  stat.th  \n",
       "0        0        0  \n",
       "1        0        0  \n",
       "2        0        1  \n",
       "3        0        1  \n",
       "4        0        1  \n",
       "\n",
       "[5 rows x 203 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(csv_path/'train.csv', delimiter=delimiter) \n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2366, 203)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HAL_ID</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>chim.anal</th>\n",
       "      <th>chim.cata</th>\n",
       "      <th>chim.chem</th>\n",
       "      <th>chim.cris</th>\n",
       "      <th>chim.geni</th>\n",
       "      <th>chim.inor</th>\n",
       "      <th>chim.mate</th>\n",
       "      <th>...</th>\n",
       "      <th>spi.other</th>\n",
       "      <th>spi.plasma</th>\n",
       "      <th>spi.signal</th>\n",
       "      <th>spi.tron</th>\n",
       "      <th>stat.ap</th>\n",
       "      <th>stat.co</th>\n",
       "      <th>stat.me</th>\n",
       "      <th>stat.ml</th>\n",
       "      <th>stat.ot</th>\n",
       "      <th>stat.th</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>halshs-00183267</td>\n",
       "      <td>La place des principes dans la physique mathém...</td>\n",
       "      <td>Nous nous proposons de tenter de comprendre co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hal-00770557</td>\n",
       "      <td>SONDY : une plateforme open-source d'analyse e...</td>\n",
       "      <td>Ce papier décrit la plateforme SONDY qui perme...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>halshs-00856441</td>\n",
       "      <td>Démarches d'investigation : exemples avec le b...</td>\n",
       "      <td>Le groupe TREMA-1 s'intéresse aux usages de re...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inria-00386689</td>\n",
       "      <td>Théorie du risque en santé publique: Applicati...</td>\n",
       "      <td>Nous introduisons une nouvelle approche pour t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hal-00659007</td>\n",
       "      <td>Connaissances mathématiques et manuels d'ensei...</td>\n",
       "      <td>Ce papier présente un travail d'analyse des co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            HAL_ID                                              title  \\\n",
       "0  halshs-00183267  La place des principes dans la physique mathém...   \n",
       "1     hal-00770557  SONDY : une plateforme open-source d'analyse e...   \n",
       "2  halshs-00856441  Démarches d'investigation : exemples avec le b...   \n",
       "3   inria-00386689  Théorie du risque en santé publique: Applicati...   \n",
       "4     hal-00659007  Connaissances mathématiques et manuels d'ensei...   \n",
       "\n",
       "                                            abstract  chim.anal  chim.cata  \\\n",
       "0  Nous nous proposons de tenter de comprendre co...          0          0   \n",
       "1  Ce papier décrit la plateforme SONDY qui perme...          0          0   \n",
       "2  Le groupe TREMA-1 s'intéresse aux usages de re...          0          0   \n",
       "3  Nous introduisons une nouvelle approche pour t...          0          0   \n",
       "4  Ce papier présente un travail d'analyse des co...          0          0   \n",
       "\n",
       "   chim.chem  chim.cris  chim.geni  chim.inor  chim.mate  ...  spi.other  \\\n",
       "0          0          0          0          0          0  ...          0   \n",
       "1          0          0          0          0          0  ...          0   \n",
       "2          0          0          0          0          0  ...          0   \n",
       "3          0          0          0          0          0  ...          0   \n",
       "4          0          0          0          0          0  ...          0   \n",
       "\n",
       "   spi.plasma  spi.signal  spi.tron  stat.ap  stat.co  stat.me  stat.ml  \\\n",
       "0           0           0         0        0        0        0        0   \n",
       "1           0           0         0        0        0        0        0   \n",
       "2           0           0         0        0        0        0        0   \n",
       "3           0           0         0        0        0        0        0   \n",
       "4           0           0         0        0        0        0        0   \n",
       "\n",
       "   stat.ot  stat.th  \n",
       "0        0        0  \n",
       "1        0        0  \n",
       "2        0        0  \n",
       "3        0        1  \n",
       "4        0        0  \n",
       "\n",
       "[5 rows x 203 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = pd.read_csv(csv_path/'dev.csv', delimiter='\\t') \n",
    "print(df_valid.shape)\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2370, 203)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HAL_ID</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>chim.anal</th>\n",
       "      <th>chim.cata</th>\n",
       "      <th>chim.chem</th>\n",
       "      <th>chim.cris</th>\n",
       "      <th>chim.geni</th>\n",
       "      <th>chim.inor</th>\n",
       "      <th>chim.mate</th>\n",
       "      <th>...</th>\n",
       "      <th>spi.other</th>\n",
       "      <th>spi.plasma</th>\n",
       "      <th>spi.signal</th>\n",
       "      <th>spi.tron</th>\n",
       "      <th>stat.ap</th>\n",
       "      <th>stat.co</th>\n",
       "      <th>stat.me</th>\n",
       "      <th>stat.ml</th>\n",
       "      <th>stat.ot</th>\n",
       "      <th>stat.th</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inria-00494835</td>\n",
       "      <td>Modélisation des dépassements de seuils pour u...</td>\n",
       "      <td>La modélisation des événements extrêmes est de...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inria-00386743</td>\n",
       "      <td>Estimation de la densité spectrale d'un champ ...</td>\n",
       "      <td>Dans ce papier, nous étudions l'estimation de ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inria-00494779</td>\n",
       "      <td>Analyse de données avec R - Complémentarité de...</td>\n",
       "      <td>L'objectif de cet exposé est de présenter les ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hal-02017267</td>\n",
       "      <td>Changement de regard sur les figures : une étu...</td>\n",
       "      <td>Cette recherche entre en résonnance avec les t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hal-00530279</td>\n",
       "      <td>Analyse de sensibilité pour l'étude des paramè...</td>\n",
       "      <td>Le but du papier est d'étudier les paramètres ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           HAL_ID                                              title  \\\n",
       "0  inria-00494835  Modélisation des dépassements de seuils pour u...   \n",
       "1  inria-00386743  Estimation de la densité spectrale d'un champ ...   \n",
       "2  inria-00494779  Analyse de données avec R - Complémentarité de...   \n",
       "3    hal-02017267  Changement de regard sur les figures : une étu...   \n",
       "4    hal-00530279  Analyse de sensibilité pour l'étude des paramè...   \n",
       "\n",
       "                                            abstract  chim.anal  chim.cata  \\\n",
       "0  La modélisation des événements extrêmes est de...          0          0   \n",
       "1  Dans ce papier, nous étudions l'estimation de ...          0          0   \n",
       "2  L'objectif de cet exposé est de présenter les ...          0          0   \n",
       "3  Cette recherche entre en résonnance avec les t...          0          0   \n",
       "4  Le but du papier est d'étudier les paramètres ...          0          0   \n",
       "\n",
       "   chim.chem  chim.cris  chim.geni  chim.inor  chim.mate  ...  spi.other  \\\n",
       "0          0          0          0          0          0  ...          0   \n",
       "1          0          0          0          0          0  ...          0   \n",
       "2          0          0          0          0          0  ...          0   \n",
       "3          0          0          0          0          0  ...          0   \n",
       "4          0          0          0          0          0  ...          0   \n",
       "\n",
       "   spi.plasma  spi.signal  spi.tron  stat.ap  stat.co  stat.me  stat.ml  \\\n",
       "0           0           0         0        0        0        0        0   \n",
       "1           0           0         0        0        0        0        0   \n",
       "2           0           0         0        0        0        0        0   \n",
       "3           0           0         0        0        0        0        0   \n",
       "4           0           0         0        0        0        0        0   \n",
       "\n",
       "   stat.ot  stat.th  \n",
       "0        0        1  \n",
       "1        0        1  \n",
       "2        0        1  \n",
       "3        0        0  \n",
       "4        0        1  \n",
       "\n",
       "[5 rows x 203 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(csv_path/'test.csv', delimiter='\\t') \n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get list of labels from DF columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label columns:  ['chim.anal', 'chim.cata', 'chim.chem', 'chim.cris', 'chim.geni', 'chim.inor', 'chim.mate', 'chim.theo', 'info.comp', 'info.eiah', 'info.info-ai', 'info.info-ao', 'info.info-ar', 'info.info-au', 'info.info-bi', 'info.info-bt', 'info.info-cc', 'info.info-ce', 'info.info-cg', 'info.info-cl', 'info.info-cr', 'info.info-cv', 'info.info-cy', 'info.info-db', 'info.info-dc', 'info.info-dl', 'info.info-dm', 'info.info-ds', 'info.info-es', 'info.info-et', 'info.info-fl', 'info.info-gl', 'info.info-gr', 'info.info-gt', 'info.info-hc', 'info.info-ia', 'info.info-im', 'info.info-ir', 'info.info-it', 'info.info-iu', 'info.info-lg', 'info.info-lo', 'info.info-ma', 'info.info-mc', 'info.info-mm', 'info.info-mo', 'info.info-ms', 'info.info-na', 'info.info-ne', 'info.info-ni', 'info.info-oh', 'info.info-os', 'info.info-pf', 'info.info-pl', 'info.info-rb', 'info.info-ro', 'info.info-sc', 'info.info-sd', 'info.info-se', 'info.info-si', 'info.info-sy', 'info.info-ti', 'info.info-ts', 'info.info-tt', 'info.info-wb', 'info.mus', 'info.par', 'math.math-ac', 'math.math-ag', 'math.math-ap', 'math.math-at', 'math.math-ca', 'math.math-co', 'math.math-ct', 'math.math-cv', 'math.math-dg', 'math.math-ds', 'math.math-fa', 'math.math-gm', 'math.math-gr', 'math.math-ho', 'math.math-it', 'math.math-lo', 'math.math-mg', 'math.math-mp', 'math.math-na', 'math.math-nt', 'math.math-oa', 'math.math-oc', 'math.math-pr', 'math.math-ra', 'math.math-rt', 'math.math-sp', 'math.math-st', 'nlin.nlin-ao', 'nlin.nlin-cd', 'nlin.nlin-cg', 'nlin.nlin-ps', 'nlin.nlin-si', 'phys.astr', 'phys.cond', 'phys.grqc', 'phys.hexp', 'phys.hist', 'phys.hthe', 'phys.meca', 'phys.mphy', 'phys.nexp', 'phys.nucl', 'phys.phys', 'phys.qphy', 'qfin.cp', 'qfin.gn', 'qfin.rm', 'qfin.st', 'scco.comp', 'scco.ling', 'scco.neur', 'scco.psyc', 'sde.be', 'sde.es', 'sde.ie', 'sde.mcg', 'sde.plan', 'sdu.astr', 'sdu.envi', 'sdu.ocean', 'sdu.other', 'sdu.stu', 'sdv.aen', 'sdv.ba', 'sdv.bbm', 'sdv.bc', 'sdv.bdd', 'sdv.bdlr', 'sdv.bibs', 'sdv.bio', 'sdv.bv', 'sdv.can', 'sdv.ee', 'sdv.eth', 'sdv.gen', 'sdv.ib', 'sdv.ida', 'sdv.mhep', 'sdv.mp', 'sdv.neu', 'sdv.ot', 'sdv.sa', 'sdv.sp', 'sdv.spee', 'shs.anthro-bio', 'shs.anthro-se', 'shs.archeo', 'shs.archi', 'shs.art', 'shs.demo', 'shs.droit', 'shs.eco', 'shs.edu', 'shs.envir', 'shs.genre', 'shs.geo', 'shs.gestion', 'shs.hisphilso', 'shs.hist', 'shs.info', 'shs.langue', 'shs.litt', 'shs.museo', 'shs.musiq', 'shs.phil', 'shs.psy', 'shs.relig', 'shs.scipo', 'shs.socio', 'shs.sport', 'shs.stat', 'spi.acou', 'spi.auto', 'spi.elec', 'spi.energ', 'spi.fluid', 'spi.gciv', 'spi.gproc', 'spi.mat', 'spi.meca', 'spi.nano', 'spi.nrj', 'spi.opti', 'spi.other', 'spi.plasma', 'spi.signal', 'spi.tron', 'stat.ap', 'stat.co', 'stat.me', 'stat.ml', 'stat.ot', 'stat.th']\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "cols = df_train.columns\n",
    "label_cols = list(cols[3:])\n",
    "num_labels = len(label_cols)\n",
    "print('Label columns: ', label_cols)\n",
    "print(num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle rows\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True) \n",
    "df_valid = df_valid.sample(frac=1).reset_index(drop=True) \n",
    "df_test = df_test.sample(frac=1).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HAL_ID</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>chim.anal</th>\n",
       "      <th>chim.cata</th>\n",
       "      <th>chim.chem</th>\n",
       "      <th>chim.cris</th>\n",
       "      <th>chim.geni</th>\n",
       "      <th>chim.inor</th>\n",
       "      <th>chim.mate</th>\n",
       "      <th>...</th>\n",
       "      <th>spi.plasma</th>\n",
       "      <th>spi.signal</th>\n",
       "      <th>spi.tron</th>\n",
       "      <th>stat.ap</th>\n",
       "      <th>stat.co</th>\n",
       "      <th>stat.me</th>\n",
       "      <th>stat.ml</th>\n",
       "      <th>stat.ot</th>\n",
       "      <th>stat.th</th>\n",
       "      <th>one_hot_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hal-00554461</td>\n",
       "      <td>Utilisation des Techniques Ultrasonores pour l...</td>\n",
       "      <td>L'huile d'Argan et l'huile d'olive sont parmi ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hal-01464426</td>\n",
       "      <td>Classification d'objets 3D par extraction de s...</td>\n",
       "      <td>Dans cet article, nous proposons une nouvelle ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hal-03362118</td>\n",
       "      <td>Identification rapide des caractéristiques de ...</td>\n",
       "      <td>Dans cette étude, nous nous intéressons à la v...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hal-01300013</td>\n",
       "      <td>Potentiel du contrôle ultrasonore d’une plaque...</td>\n",
       "      <td>L'inspection en service de structures internes...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cea-02562688</td>\n",
       "      <td>Comparaison des codes de calcul de dose Monte-...</td>\n",
       "      <td>Les systèmes de planification de traitement (T...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         HAL_ID                                              title  \\\n",
       "0  hal-00554461  Utilisation des Techniques Ultrasonores pour l...   \n",
       "1  hal-01464426  Classification d'objets 3D par extraction de s...   \n",
       "2  hal-03362118  Identification rapide des caractéristiques de ...   \n",
       "3  hal-01300013  Potentiel du contrôle ultrasonore d’une plaque...   \n",
       "4  cea-02562688  Comparaison des codes de calcul de dose Monte-...   \n",
       "\n",
       "                                            abstract  chim.anal  chim.cata  \\\n",
       "0  L'huile d'Argan et l'huile d'olive sont parmi ...          0          0   \n",
       "1  Dans cet article, nous proposons une nouvelle ...          0          0   \n",
       "2  Dans cette étude, nous nous intéressons à la v...          0          0   \n",
       "3  L'inspection en service de structures internes...          0          0   \n",
       "4  Les systèmes de planification de traitement (T...          0          0   \n",
       "\n",
       "   chim.chem  chim.cris  chim.geni  chim.inor  chim.mate  ...  spi.plasma  \\\n",
       "0          0          0          0          0          0  ...           0   \n",
       "1          0          0          0          0          0  ...           0   \n",
       "2          0          0          0          0          0  ...           0   \n",
       "3          0          0          0          0          0  ...           0   \n",
       "4          0          0          0          0          0  ...           0   \n",
       "\n",
       "   spi.signal  spi.tron  stat.ap  stat.co  stat.me  stat.ml  stat.ot  stat.th  \\\n",
       "0           0         0        0        0        0        0        0        0   \n",
       "1           0         0        0        0        0        0        0        0   \n",
       "2           0         0        0        0        0        0        0        0   \n",
       "3           0         0        0        0        0        0        0        0   \n",
       "4           0         0        0        0        1        0        0        0   \n",
       "\n",
       "                                      one_hot_labels  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[5 rows x 204 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['one_hot_labels'] = list(df_train[label_cols].values)\n",
    "df_valid['one_hot_labels'] = list(df_valid[label_cols].values)\n",
    "df_test['one_hot_labels'] = list(df_test[label_cols].values)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to DF values to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = list(df_train.one_hot_labels.values)\n",
    "train_text = list(df_train.abstract.values)\n",
    "\n",
    "valid_labels = list(df_valid.one_hot_labels.values)\n",
    "valid_text = list(df_valid.abstract.values)\n",
    "\n",
    "test_labels = list(df_test.one_hot_labels.values)\n",
    "test_text = list(df_test.abstract.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize texts and gete input_ids + attention masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/flaubert/flaubert_base_cased/resolve/main/config.json from cache at /home/haytame/.cache/huggingface/transformers/0b9ef58865bb61b2a44569c51b24b441c7b6b49ba63c659fc4ad5d61ffa011d6.c03a6cc0529664af7ebd7b4b385954d9cd0071c3d965d9377ab407e2eaa06918\n",
      "Model config FlaubertConfig {\n",
      "  \"_name_or_path\": \"flaubert/flaubert_base_cased\",\n",
      "  \"amp\": 1,\n",
      "  \"architectures\": [\n",
      "    \"FlaubertWithLMHeadModel\"\n",
      "  ],\n",
      "  \"asm\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_index\": 0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"bptt\": 512,\n",
      "  \"causal\": false,\n",
      "  \"clip_grad_norm\": 5,\n",
      "  \"dropout\": 0.1,\n",
      "  \"emb_dim\": 768,\n",
      "  \"embed_init_std\": 0.02209708691207961,\n",
      "  \"encoder_only\": true,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_index\": 1,\n",
      "  \"fp16\": true,\n",
      "  \"gelu_activation\": true,\n",
      "  \"group_by_size\": true,\n",
      "  \"id2lang\": {\n",
      "    \"0\": \"fr\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder\": true,\n",
      "  \"lang2id\": {\n",
      "    \"fr\": 0\n",
      "  },\n",
      "  \"lang_id\": 0,\n",
      "  \"langs\": [\n",
      "    \"fr\"\n",
      "  ],\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"lg_sampling_factor\": -1,\n",
      "  \"lgs\": \"fr\",\n",
      "  \"mask_index\": 5,\n",
      "  \"mask_token_id\": 0,\n",
      "  \"max_batch_size\": 0,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_vocab\": -1,\n",
      "  \"mlm_steps\": [\n",
      "    [\n",
      "      \"fr\",\n",
      "      null\n",
      "    ]\n",
      "  ],\n",
      "  \"model_type\": \"flaubert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_langs\": 1,\n",
      "  \"n_layers\": 12,\n",
      "  \"pad_index\": 2,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"pre_norm\": false,\n",
      "  \"sample_alpha\": 0,\n",
      "  \"share_inout_emb\": true,\n",
      "  \"sinusoidal_embeddings\": false,\n",
      "  \"start_n_top\": 5,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokens_per_batch\": -1,\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"unk_index\": 3,\n",
      "  \"use_lang_emb\": true,\n",
      "  \"vocab_size\": 68729,\n",
      "  \"word_blank\": 0,\n",
      "  \"word_dropout\": 0,\n",
      "  \"word_keep\": 0.1,\n",
      "  \"word_mask\": 0.8,\n",
      "  \"word_mask_keep_rand\": \"0.8,0.1,0.1\",\n",
      "  \"word_pred\": 0.15,\n",
      "  \"word_rand\": 0.1,\n",
      "  \"word_shuffle\": 0\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/flaubert/flaubert_base_cased/resolve/main/vocab.json from cache at /home/haytame/.cache/huggingface/transformers/539b03cc777c9a7ade2e61b349c1a2718ebc34b2fdc1be23661c4af4794d19c7.54f2160ec9b24036aa3659b29dd457b2706dadb6bb37452f66662e009c6f06cd\n",
      "loading file https://huggingface.co/flaubert/flaubert_base_cased/resolve/main/merges.txt from cache at /home/haytame/.cache/huggingface/transformers/4b497a793ad900a992634fcfc9ff415350e04b1b860f01dab9334c5989f9eb81.5a23e82e9ed3454c1a87fe4caf3681d0254d11a16bddc4059bc146257abb989b\n",
      "loading file https://huggingface.co/flaubert/flaubert_base_cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/flaubert/flaubert_base_cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/flaubert/flaubert_base_cased/resolve/main/tokenizer_config.json from cache at /home/haytame/.cache/huggingface/transformers/4bfcc62bbe7304f2c09f0b03cb66e87ed0d47da9bf069e5fff3bcf1bc848af91.a21d5897a986b8d1fed966dd1c99dda877a45f1904b91680ccb7cccb9c41a95b\n",
      "loading configuration file https://huggingface.co/flaubert/flaubert_base_cased/resolve/main/config.json from cache at /home/haytame/.cache/huggingface/transformers/0b9ef58865bb61b2a44569c51b24b441c7b6b49ba63c659fc4ad5d61ffa011d6.c03a6cc0529664af7ebd7b4b385954d9cd0071c3d965d9377ab407e2eaa06918\n",
      "Model config FlaubertConfig {\n",
      "  \"_name_or_path\": \"flaubert/flaubert_base_cased\",\n",
      "  \"amp\": 1,\n",
      "  \"architectures\": [\n",
      "    \"FlaubertWithLMHeadModel\"\n",
      "  ],\n",
      "  \"asm\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_index\": 0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"bptt\": 512,\n",
      "  \"causal\": false,\n",
      "  \"clip_grad_norm\": 5,\n",
      "  \"dropout\": 0.1,\n",
      "  \"emb_dim\": 768,\n",
      "  \"embed_init_std\": 0.02209708691207961,\n",
      "  \"encoder_only\": true,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_index\": 1,\n",
      "  \"fp16\": true,\n",
      "  \"gelu_activation\": true,\n",
      "  \"group_by_size\": true,\n",
      "  \"id2lang\": {\n",
      "    \"0\": \"fr\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder\": true,\n",
      "  \"lang2id\": {\n",
      "    \"fr\": 0\n",
      "  },\n",
      "  \"lang_id\": 0,\n",
      "  \"langs\": [\n",
      "    \"fr\"\n",
      "  ],\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"lg_sampling_factor\": -1,\n",
      "  \"lgs\": \"fr\",\n",
      "  \"mask_index\": 5,\n",
      "  \"mask_token_id\": 0,\n",
      "  \"max_batch_size\": 0,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_vocab\": -1,\n",
      "  \"mlm_steps\": [\n",
      "    [\n",
      "      \"fr\",\n",
      "      null\n",
      "    ]\n",
      "  ],\n",
      "  \"model_type\": \"flaubert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_langs\": 1,\n",
      "  \"n_layers\": 12,\n",
      "  \"pad_index\": 2,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"pre_norm\": false,\n",
      "  \"sample_alpha\": 0,\n",
      "  \"share_inout_emb\": true,\n",
      "  \"sinusoidal_embeddings\": false,\n",
      "  \"start_n_top\": 5,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokens_per_batch\": -1,\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"unk_index\": 3,\n",
      "  \"use_lang_emb\": true,\n",
      "  \"vocab_size\": 68729,\n",
      "  \"word_blank\": 0,\n",
      "  \"word_dropout\": 0,\n",
      "  \"word_keep\": 0.1,\n",
      "  \"word_mask\": 0.8,\n",
      "  \"word_mask_keep_rand\": \"0.8,0.1,0.1\",\n",
      "  \"word_pred\": 0.15,\n",
      "  \"word_rand\": 0.1,\n",
      "  \"word_shuffle\": 0\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_length = 512 # max sequence length\n",
    "model_name = \"flaubert/flaubert_base_cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer outputs:  dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "encodings_train = tokenizer.batch_encode_plus(train_text,max_length=max_length,padding='max_length',truncation=True) \n",
    "print('tokenizer outputs: ', encodings_train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer outputs:  dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "encodings_valid = tokenizer.batch_encode_plus(valid_text,max_length=max_length,padding='max_length',truncation=True) \n",
    "print('tokenizer outputs: ', encodings_valid.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer outputs:  dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "encodings_test = tokenizer.batch_encode_plus(test_text,max_length=max_length,padding='max_length',truncation=True)\n",
    "print('tokenizer outputs: ', encodings_test.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids = encodings_train['input_ids'] # tokenized and encoded sentences\n",
    "train_attention_masks = encodings_train['attention_mask'] # attention masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_input_ids = encodings_valid['input_ids']\n",
    "valid_attention_masks = encodings_valid['attention_mask']\n",
    "test_input_ids = encodings_test['input_ids']\n",
    "test_attention_masks = encodings_test['attention_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to tensors and Make Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs_tensor = torch.tensor(np.array(train_input_ids))\n",
    "train_masks_tensor = torch.tensor(np.array(train_attention_masks))\n",
    "train_labels_tensor = torch.tensor(np.array(train_labels))\n",
    "\n",
    "validation_inputs_tensor = torch.tensor(np.array(valid_input_ids))\n",
    "validation_masks_tensor = torch.tensor(np.array(valid_attention_masks))\n",
    "validation_labels_tensor = torch.tensor(np.array(valid_labels))\n",
    "\n",
    "test_inputs_tensor = torch.tensor(np.array(test_input_ids))\n",
    "test_masks_tensor = torch.tensor(np.array(test_attention_masks))\n",
    "test_labels_tensor = torch.tensor(np.array(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a batch size for training. a power of 2 is recommended\n",
    "batch_size = 8\n",
    "\n",
    "train_data = TensorDataset(train_inputs_tensor, train_masks_tensor, train_labels_tensor)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs_tensor, validation_masks_tensor, validation_labels_tensor)\n",
    "validation_sampler = RandomSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "test_data = TensorDataset(test_inputs_tensor, test_masks_tensor, test_labels_tensor)\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path('FlauBERT/dataloaders/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_dataloader,save_path/f'train_data_loader-{batch_size}-{max_length}')\n",
    "torch.save(validation_dataloader,save_path/f'validation_data_loader-{batch_size}-{max_length}')\n",
    "torch.save(test_dataloader,save_path/f'test_data_loader-{batch_size}-{max_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
